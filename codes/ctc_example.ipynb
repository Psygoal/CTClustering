{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f015b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from CTClustering.clustering import CTC\n",
    "from CTClustering.ctc import run_ctc_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75c703",
   "metadata": {},
   "source": [
    "# 1 Training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed2bc44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded configuration from ./config.json.\n",
      "\n",
      "Initializing CTC class with the following parameters:\n",
      "{\n",
      "    \"dim\": 2,\n",
      "    \"lag_time\": 1,\n",
      "    \"Px_path\": \"px.npy\",\n",
      "    \"Px_model_path\": \"px_flow.h5\",\n",
      "    \"Pxy_model_path\": \"pxy_flow.h5\",\n",
      "    \"transition_mat_path\": \"transmat.npy\"\n",
      "}\n",
      "\n",
      "Calling fit_predict method with the following combined parameters:\n",
      "{\n",
      "    \"save\": true,\n",
      "    \"ctc_model_path\": \"ctc_model.pkl\",\n",
      "    \"px_estimator_params\": {\n",
      "        \"output_dim\": 128,\n",
      "        \"reg\": 0.0001,\n",
      "        \"num_coupling_layers\": 12,\n",
      "        \"learning_rate\": 0.0003,\n",
      "        \"epochs\": 1,\n",
      "        \"batch_size\": 2048,\n",
      "        \"validation_split\": 0.3\n",
      "    },\n",
      "    \"pxy_estimator_params\": {\n",
      "        \"output_dim\": 256,\n",
      "        \"reg\": 0.0001,\n",
      "        \"num_coupling_layers\": 12,\n",
      "        \"learning_rate\": 0.0003,\n",
      "        \"epochs\": 1,\n",
      "        \"batch_size\": 2048,\n",
      "        \"validation_split\": 0.3\n",
      "    },\n",
      "    \"px_estimate_params\": {\n",
      "        \"inference_batch_size\": 200000\n",
      "    },\n",
      "    \"valley_finding_params\": {\n",
      "        \"window_length\": 50,\n",
      "        \"polyorder\": 7,\n",
      "        \"peak_distance\": 50\n",
      "    },\n",
      "    \"cal_transition_mat_params\": {\n",
      "        \"inference_batch_size\": 1000000\n",
      "    },\n",
      "    \"merging_params\": {\n",
      "        \"ds_scale\": 50,\n",
      "        \"bins\": 400,\n",
      "        \"sigma\": 2,\n",
      "        \"tolerance\": 15,\n",
      "        \"min_cluster_size\": 100,\n",
      "        \"patience\": 15,\n",
      "        \"change_patient_tolerence\": 10\n",
      "    }\n",
      "}\n",
      "========training marignal probability estimator========\n",
      "342/342 [==============================] - ETA: 0s - loss: 3.1126\n",
      "Epoch 1: val_loss improved from inf to 2.96359, saving model to px_flow.h5\n",
      "342/342 [==============================] - 54s 76ms/step - loss: 3.1126 - val_loss: 2.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========training joint probability estimator========\n",
      "684/684 [==============================] - ETA: 0s - loss: 2.1110\n",
      "Epoch 1: val_loss improved from inf to 1.86862, saving model to pxy_flow.h5\n",
      "684/684 [==============================] - 79s 74ms/step - loss: 2.1110 - val_loss: 1.8686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [02:09<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate adjaceny matrix ...\n",
      "find the largest clique ...\n",
      "self-consistent reassignment ...\n",
      "the number of changed samples is 2105\n",
      "the number of changed samples is 1946\n",
      "the number of changed samples is 532\n",
      "the number of changed samples is 271\n",
      "the number of changed samples is 159\n",
      "the number of changed samples is 74\n",
      "the number of changed samples is 44\n",
      "the number of changed samples is 25\n",
      "the number of changed samples is 20\n",
      "the number of changed samples is 15\n",
      "Change count (15) is within tolerance (15).\n",
      "CTC model is saved at ctc_model.pkl\n",
      "\n",
      "fit_predict execution finished. Found 6 clusters.\n",
      "Sample labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Script execution complete. Returning CTC instance.\n"
     ]
    }
   ],
   "source": [
    "data = np.load('data.npy')\n",
    "ctc_instance = run_ctc_from_config(data, './config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ead9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ctc_instance.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee763d",
   "metadata": {},
   "source": [
    "# 2 prediction using CTC from trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0491cfa",
   "metadata": {},
   "source": [
    "### initialize a CTC instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6324ab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = {\"dim\": 2,\n",
    "    \"lag_time\": 1,\n",
    "    \"Px_path\": \"px.npy\",\n",
    "    \"Px_model_path\": \"px_flow.h5\",\n",
    "    \"Pxy_model_path\": \"pxy_flow.h5\",\n",
    "    \"transition_mat_path\": \"transmat.npy\"}\n",
    "\n",
    "ctc = CTC(**init_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135adfa",
   "metadata": {},
   "source": [
    "### load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21afd649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========load the trained marignal probability estimator at px_flow.h5========\n",
      "========load the trained joint probability estimator at pxy_flow.h5========\n",
      "CTC is successfully loaded\n"
     ]
    }
   ],
   "source": [
    "px_estimator_params = {\n",
    "    \"output_dim\": 128,\n",
    "    \"num_coupling_layers\": 12\n",
    "  }\n",
    "\n",
    "pxy_estimator_params = {\n",
    "    \"output_dim\": 256,\n",
    "    \"num_coupling_layers\": 12\n",
    "  }\n",
    "    \n",
    "ctc.load('ctc_model.pkl',px_estimator_params,pxy_estimator_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37af51",
   "metadata": {},
   "source": [
    "### predict unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fb0c06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 1 1 0 1 4 1 4]\n"
     ]
    }
   ],
   "source": [
    "predict_data = np.random.normal(size=(10,2))\n",
    "predict_label = ctc.predict(predict_data)\n",
    "print(predict_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
